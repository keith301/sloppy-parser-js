# sloppy-parser-js  
### *Because your LLM lied about outputting JSON.*

[![Tests](https://img.shields.io/badge/tests-22%2F29%20passing-yellow)]()
[![License](https://img.shields.io/badge/license-MIT-blue)]()

Have you ever asked an LLM for JSON and received:

- JSON-ish  
- YAML-ish  
- spiritual guidance  
- a TED talk  
- {foo: "bar" btw I'll do that tool call now}  
- or my personal favorite:  
  Here's your JSON! {don't: worry, no: quotes}

Yeah. Same.

**sloppy-parser-js** is a zero-dependency, browser-first parser that takes whatever ‚Äústructured output‚Äù your AI model *thinks* it produced‚Ä¶  
and gently repairs it into strict JSON **without losing the surrounding narration or tool-call context**.

It doesn‚Äôt judge.  
It just fixes things.

---

# Why This Exists

Because every agent framework on Earth requires:
- clean JSON  
- tool calls extracted from narration  
- no hallucinated backticks  
- and definitely no ‚Äúbtw‚Äù inside your {}

But LLMs‚Ä¶  
LLMs are like:

"Sure here's your JSON üôÉ"  
{foo:bar baz:qux # lmao}

So this library:
- segments the output into text vs object  
- repairs objects using soft grammar + read-repair  
- returns strict JSON (single or array)  
- preserves narration perfectly  

It‚Äôs not strict.  
It‚Äôs not pedantic.  
It‚Äôs a **permission system** that tries to understand the LLM‚Äôs *intent*.

---

# TL;DR Example

parseJson("{foo:bar baz:qux}")  
‚Üí { foo: "bar", baz: "qux" }

parseRawOutput("I'll do something\n{tool: first}\nand then\n{tool: second params:{x:1}}")  
‚Üí  
- text: "I'll do something"  
- object: {tool:"first"}  
- text: "and then"  
- object: {tool:"second", params:{x:1}}

---

# What This Actually Does

## 1) Segments your LLM output  
Into a deterministic sequence of:

- {type:"text", text:"..."}  
- {type:"object", object:{‚Ä¶}, raw:"...", repairedText:"..."}  

Preserving:
- order  
- narration  
- derailments  
- tool calls  
- the entire chaotic vibe

Perfect for UI and agent pipelines.

---

## 2) Repairs the objects  
With techniques ranging from polite nudges to spiritual duct tape:

- quote unquoted keys  
- quote unquoted values  
- infer commas  
- remove inline comments  
- normalize Unicode quotes  
- merge multiword keys  
- fix mismatched braces  
- handle YAML-like patterns  
- reconstruct arrays  
- drop trailing nonsense  

Then converts repaired text ‚Üí strict JSON ‚Üí JSON.parse().

If JSON-ish fails ‚Üí try YAML-ish.  
If YAML-ish fails ‚Üí deeper heuristic repairs.  
If everything fails ‚Üí you fed it a war crime.

---

## 3) Outputs usable JSON

Rules:
- 0 objects ‚Üí null  
- 1 object ‚Üí return it  
- many objects ‚Üí return array (ordered)  

Great for:
- workflow engines  
- tool-call runners  
- RIAs/agent UIs  
- streaming interpreters  
- anywhere you need ‚Äújust the structured bits please‚Äù

---

# Install

npm install sloppy-parser-js

---

# Philosophy

### **This is not a strict parser.**  
Strict parsing died on impact.

### **Grammar is soft. Repairs are contextual.**  
If you're parsing a VALUE, you know a comment isn‚Äôt part of it.

Example:  
name: Keith  # obviously  
‚Üí "name": "Keith"

### **Text stays text. Objects become JSON.**  
No more ‚Äúsorry I tried to split the narration from the tool call myself.‚Äù

### **Zero dependencies.**  
Because the moment you import a YAML library,  
someone opens an issue about anchors, tags, or multi-doc streams.

---

# Real LLM Chaos (and how it parses)

Input:
I think this will work...
{foo:1}
Anyway let me tell you about
the time I broke JSON parsing
{bar:2 baz:3}
Okay I'm done now

Raw output (segmented):
text ‚Üí object ‚Üí text ‚Üí object ‚Üí text

JSON projection:
[{foo:1}, {bar:2, baz:3}]

---

# API

parseRawOutput(input)  
‚Üí ordered list of text + object blocks

parseJson(input)  
‚Üí null | object | array of objects  

---

# How It Works (Architecture)

Raw LLM Output  
‚Üí Preprocessor  
‚Üí Soft Tokenizer (MAYBE tokens, scored)  
‚Üí Soft Parser (backtracking, grammar hints)  
‚Üí Read-Repair Reconstructor  
‚Üí Strict JSON string  
‚Üí JSON.parse()  
‚Üí Beautiful clean object(s)

Repairs happen *during* reconstruction ‚Äî not after.  
Context drives correctness.

---

# Test Philosophy

Every new LLM horror scenario becomes a test case.

Tests assert:
1) the segmented raw blocks  
2) the extracted JSON projection  

Examples include:
- missing commas  
- missing quotes  
- inline comments  
- YAML lists  
- apostrophes in text  
- back-to-back objects  
- emoji values  
- nested objects with bare keys  
- malformed indentation  
- fenced blocks  
- NPR-host narration  
- multi-tool-call streaming fragments  

The library improves by growing its trauma dataset.

---

# Current Status

22/29 tests passing.

Working:
- missing quotes  
- missing commas  
- inline comments  
- nested bare-key objects  
- emoji  
- unicode quotes  
- arrays  
- narration + object interleave  
- double/triple tool calls with derailments  

In progress:
- YAML lists with inconsistent indentation  
- YAML mixed with inline JSON  
- multiline values  
- some pathological missing-brace scenarios  

---

# Roadmap

- Better YAML-ish reconstruction  
- Streaming parser  
- Visualization/debug tools  
- WASM core  
- Python port (sloppy-parser-py)  
- Agent wrapper for OpenAI-compatible API  
- Schema hints for smarter repair scoring  

---

# Contributing

Bring your horrors.

We don‚Äôt want your code.  
We want your *nightmare test cases*.  

The worse the sample, the better the parser becomes.

PRs should include:
- the cursed input  
- expected segmented blocks  
- expected JSON projection  

---

# License  
MIT

---

# A Note on Philosophy

Strict parsers reject malformed input.  
Humans don‚Äôt speak in strict syntax.

This library assumes:
- the model tried  
- the structure is implied  
- the intent is clear  
- context can fix what syntax broke

sloppy-parser-js is built on the idea that  
**repair is more useful than rejection**.

Grace, not strictness.